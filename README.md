# Beyond GPT: Understanding the Advancements and Challenges in Large Language Models

**Author**: Jatin Wig  
**Institution**: BITS Pilani  
**Email**: wigjatin2@gmail.com  
**Date**: April 2025

This is my bachelor's thesis exploring the evolution of Large Language Models (LLMs) beyond GPT. It covers transformer architecture, tokenization, scaling laws, RLHF, hallucinations, multimodal systems, and future AGI challenges.

## Highlights
- Transformer architecture explained from scratch
- PyTorch snippets and mathematical formulations
- Industry use cases (education, healthcare, finance, legal)
- Deep analysis of bias, hallucinations, and energy use
- Future directions in multimodal AI and regulatory design

## License
This work is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).

## Cite this work
If you found this thesis useful, cite it via DOI (coming soon from Zenodo) or use this GitHub repo.
